<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-02-15T14:33:24+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Quentin’s site</title><subtitle>PhD Student in Deep Reinforcement Learning</subtitle><author><name>Quentin GALLOUÉDEC</name></author><entry><title type="html">OpenAI Gym environment for Franka Emika Panda robot</title><link href="http://localhost:4000/posts/2021/02/openai-environment-for-franka-emika-panda-robot/" rel="alternate" type="text/html" title="OpenAI Gym environment for Franka Emika Panda robot" /><published>2021-02-13T00:00:00+01:00</published><updated>2021-02-13T00:00:00+01:00</updated><id>http://localhost:4000/posts/2021/02/panda-gym</id><content type="html" xml:base="http://localhost:4000/posts/2021/02/openai-environment-for-franka-emika-panda-robot/">&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/qgallouedec/panda-gym/master/docs/demo.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;learning-is-cool&quot;&gt;Learning is cool&lt;/h1&gt;

&lt;p&gt;It is no longer necessary to explain the genesis of reinforcement learning and the great applications it has. There are many school cases and the learning algorithms are more and more interesting.
I find them particularly fascinating when they can be explained with very simple ideas.&lt;/p&gt;

&lt;p&gt;One of the basic environments proposed by OpenAI to train reinforcement learning algorithms are the environments of the &lt;a href=&quot;https://openai.com/blog/ingredients-for-robotics-research/&quot;&gt;Fetch robot&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This Fetch environments are an excellent starting point to test RL algorithms.
But, you may have noticed that these environments are based on &lt;a href=&quot;http://www.mujoco.org&quot;&gt;MuJoCo&lt;/a&gt;: a very powerful physics engine, but not free.&lt;/p&gt;

&lt;p&gt;In this work, I tried to reproduce as faithfully as possible these environments based on a &lt;strong&gt;free&lt;/strong&gt; and &lt;strong&gt;open-source&lt;/strong&gt; physics engine: &lt;a href=&quot;https://pybullet.org/wordpress/&quot;&gt;Bullet&lt;/a&gt;.
I also chose to use another robot arm, with more joints, and a different gripper: the &lt;strong&gt;Franka Emika Panda robot&lt;/strong&gt;.
Source code is available on &lt;a href=&quot;https://github.com/qgallouedec/panda-gym&quot;&gt;GitHub&lt;/a&gt;. 
In the following, I will present you the result of this work, and show you some examples of use.&lt;/p&gt;

&lt;h1 id=&quot;installation-and-usage&quot;&gt;Installation and usage&lt;/h1&gt;

&lt;p&gt;Using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip&lt;/code&gt; you can install &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;panda-gym&lt;/code&gt;by running&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;panda-gym
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, in a python script:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;gym&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;panda_gym&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gym&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'PandaReach-v0'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;render&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;obs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_space&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# random action
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For those of you who are used to the OpenAI gym environments, you will notice that the rendering functionality is not handled in the usual way. It is passed as an argument to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make&lt;/code&gt; function. So you don’t need to call the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;render()&lt;/code&gt; function.&lt;/p&gt;

&lt;h1 id=&quot;train-panda_gym-with-hindsight-experience-replay&quot;&gt;Train &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;panda_gym&lt;/code&gt; with Hindsight Experience Replay&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1707.01495&quot;&gt;Hindsight Experience Replay&lt;/a&gt; (HER) was introduced in 2017 by Andrychowicz et al.. The key idea of HER is to see a fail as a success, but with another goal.
It is a method that has shown very promising results in robotic environments. Since the space of action and the space of observation are identical, the results should be very similar.&lt;/p&gt;

&lt;div class=&quot;infogram-embed&quot; data-id=&quot;904c3193-f551-4da8-9c37-36ff4e47fe12&quot; data-type=&quot;interactive&quot; data-title=&quot;Courbes avec marge d&amp;amp;#39;erreur&quot;&gt;
&lt;/div&gt;
&lt;script&gt;
!function(e,i,n,s){
  var t=&quot;InfogramEmbeds&quot;,d=e.getElementsByTagName(&quot;script&quot;)[0];
  if(window[t]&amp;&amp;window[t].initialized)window[t].process&amp;&amp;window[t].process();
  else if(!e.getElementById(n)){
    var o=e.createElement(&quot;script&quot;);o.async=1,o.id=n,o.src=&quot;https://e.infogram.com/js/dist/embed-loader-min.js&quot;,d.parentNode.insertBefore(o,d)
    }
  }(document,0,&quot;infogram-async&quot;);
&lt;/script&gt;</content><author><name>Quentin GALLOUÉDEC</name></author><category term="PyBullet" /><category term="OpenAI Gym" /><category term="Robotics" /><category term="Reinforcement Learning" /><summary type="html"></summary></entry></feed>